{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Flow Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cancer_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  benign_0__mal_1          569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>28.11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>39.28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>188.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>2501.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.16340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.34540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.42680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.20120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.30400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radius error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.277313</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.324200</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>2.87300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>1.216853</td>\n",
       "      <td>0.551648</td>\n",
       "      <td>0.360200</td>\n",
       "      <td>0.833900</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>1.474000</td>\n",
       "      <td>4.88500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>2.866059</td>\n",
       "      <td>2.021855</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>1.606000</td>\n",
       "      <td>2.287000</td>\n",
       "      <td>3.357000</td>\n",
       "      <td>21.98000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>40.337079</td>\n",
       "      <td>45.491006</td>\n",
       "      <td>6.802000</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>24.530000</td>\n",
       "      <td>45.190000</td>\n",
       "      <td>542.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.007041</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.03113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>0.13540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>0.025890</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.39600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concave points error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.05279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>0.008266</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.023480</td>\n",
       "      <td>0.07895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractal dimension error</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.002646</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.003187</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.02984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst radius</th>\n",
       "      <td>569.0</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>36.04000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst texture</th>\n",
       "      <td>569.0</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>49.54000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst perimeter</th>\n",
       "      <td>569.0</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>251.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst area</th>\n",
       "      <td>569.0</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>4254.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst smoothness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.22260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst compactness</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>1.05800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concavity</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>1.25200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst concave points</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.29100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst symmetry</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.66380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benign_0__mal_1</th>\n",
       "      <td>569.0</td>\n",
       "      <td>0.627417</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count        mean         std         min  \\\n",
       "mean radius              569.0   14.127292    3.524049    6.981000   \n",
       "mean texture             569.0   19.289649    4.301036    9.710000   \n",
       "mean perimeter           569.0   91.969033   24.298981   43.790000   \n",
       "mean area                569.0  654.889104  351.914129  143.500000   \n",
       "mean smoothness          569.0    0.096360    0.014064    0.052630   \n",
       "mean compactness         569.0    0.104341    0.052813    0.019380   \n",
       "mean concavity           569.0    0.088799    0.079720    0.000000   \n",
       "mean concave points      569.0    0.048919    0.038803    0.000000   \n",
       "mean symmetry            569.0    0.181162    0.027414    0.106000   \n",
       "mean fractal dimension   569.0    0.062798    0.007060    0.049960   \n",
       "radius error             569.0    0.405172    0.277313    0.111500   \n",
       "texture error            569.0    1.216853    0.551648    0.360200   \n",
       "perimeter error          569.0    2.866059    2.021855    0.757000   \n",
       "area error               569.0   40.337079   45.491006    6.802000   \n",
       "smoothness error         569.0    0.007041    0.003003    0.001713   \n",
       "compactness error        569.0    0.025478    0.017908    0.002252   \n",
       "concavity error          569.0    0.031894    0.030186    0.000000   \n",
       "concave points error     569.0    0.011796    0.006170    0.000000   \n",
       "symmetry error           569.0    0.020542    0.008266    0.007882   \n",
       "fractal dimension error  569.0    0.003795    0.002646    0.000895   \n",
       "worst radius             569.0   16.269190    4.833242    7.930000   \n",
       "worst texture            569.0   25.677223    6.146258   12.020000   \n",
       "worst perimeter          569.0  107.261213   33.602542   50.410000   \n",
       "worst area               569.0  880.583128  569.356993  185.200000   \n",
       "worst smoothness         569.0    0.132369    0.022832    0.071170   \n",
       "worst compactness        569.0    0.254265    0.157336    0.027290   \n",
       "worst concavity          569.0    0.272188    0.208624    0.000000   \n",
       "worst concave points     569.0    0.114606    0.065732    0.000000   \n",
       "worst symmetry           569.0    0.290076    0.061867    0.156500   \n",
       "worst fractal dimension  569.0    0.083946    0.018061    0.055040   \n",
       "benign_0__mal_1          569.0    0.627417    0.483918    0.000000   \n",
       "\n",
       "                                25%         50%          75%         max  \n",
       "mean radius               11.700000   13.370000    15.780000    28.11000  \n",
       "mean texture              16.170000   18.840000    21.800000    39.28000  \n",
       "mean perimeter            75.170000   86.240000   104.100000   188.50000  \n",
       "mean area                420.300000  551.100000   782.700000  2501.00000  \n",
       "mean smoothness            0.086370    0.095870     0.105300     0.16340  \n",
       "mean compactness           0.064920    0.092630     0.130400     0.34540  \n",
       "mean concavity             0.029560    0.061540     0.130700     0.42680  \n",
       "mean concave points        0.020310    0.033500     0.074000     0.20120  \n",
       "mean symmetry              0.161900    0.179200     0.195700     0.30400  \n",
       "mean fractal dimension     0.057700    0.061540     0.066120     0.09744  \n",
       "radius error               0.232400    0.324200     0.478900     2.87300  \n",
       "texture error              0.833900    1.108000     1.474000     4.88500  \n",
       "perimeter error            1.606000    2.287000     3.357000    21.98000  \n",
       "area error                17.850000   24.530000    45.190000   542.20000  \n",
       "smoothness error           0.005169    0.006380     0.008146     0.03113  \n",
       "compactness error          0.013080    0.020450     0.032450     0.13540  \n",
       "concavity error            0.015090    0.025890     0.042050     0.39600  \n",
       "concave points error       0.007638    0.010930     0.014710     0.05279  \n",
       "symmetry error             0.015160    0.018730     0.023480     0.07895  \n",
       "fractal dimension error    0.002248    0.003187     0.004558     0.02984  \n",
       "worst radius              13.010000   14.970000    18.790000    36.04000  \n",
       "worst texture             21.080000   25.410000    29.720000    49.54000  \n",
       "worst perimeter           84.110000   97.660000   125.400000   251.20000  \n",
       "worst area               515.300000  686.500000  1084.000000  4254.00000  \n",
       "worst smoothness           0.116600    0.131300     0.146000     0.22260  \n",
       "worst compactness          0.147200    0.211900     0.339100     1.05800  \n",
       "worst concavity            0.114500    0.226700     0.382900     1.25200  \n",
       "worst concave points       0.064930    0.099930     0.161400     0.29100  \n",
       "worst symmetry             0.250400    0.282200     0.317900     0.66380  \n",
       "worst fractal dimension    0.071460    0.080040     0.092080     0.20750  \n",
       "benign_0__mal_1            0.000000    1.000000     1.000000     1.00000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19c5e10f860>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='benign_0__mal_1', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst concave points      -0.793566\n",
       "worst perimeter           -0.782914\n",
       "mean concave points       -0.776614\n",
       "worst radius              -0.776454\n",
       "mean perimeter            -0.742636\n",
       "worst area                -0.733825\n",
       "mean radius               -0.730029\n",
       "mean area                 -0.708984\n",
       "mean concavity            -0.696360\n",
       "worst concavity           -0.659610\n",
       "mean compactness          -0.596534\n",
       "worst compactness         -0.590998\n",
       "radius error              -0.567134\n",
       "perimeter error           -0.556141\n",
       "area error                -0.548236\n",
       "worst texture             -0.456903\n",
       "worst smoothness          -0.421465\n",
       "worst symmetry            -0.416294\n",
       "mean texture              -0.415185\n",
       "concave points error      -0.408042\n",
       "mean smoothness           -0.358560\n",
       "mean symmetry             -0.330499\n",
       "worst fractal dimension   -0.323872\n",
       "compactness error         -0.292999\n",
       "concavity error           -0.253730\n",
       "fractal dimension error   -0.077972\n",
       "symmetry error             0.006522\n",
       "texture error              0.008303\n",
       "mean fractal dimension     0.012838\n",
       "smoothness error           0.067016\n",
       "Name: benign_0__mal_1, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['benign_0__mal_1'].sort_values()[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('benign_0__mal_1', axis=1).values\n",
    "y = df['benign_0__mal_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid')) # 0 or 1\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/600\n",
      "426/426 [==============================] - 0s 1ms/sample - loss: 0.6618 - val_loss: 0.6393\n",
      "Epoch 2/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.6214 - val_loss: 0.6027\n",
      "Epoch 3/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.5828 - val_loss: 0.5601\n",
      "Epoch 4/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.5365 - val_loss: 0.5083\n",
      "Epoch 5/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.4829 - val_loss: 0.4530\n",
      "Epoch 6/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.4299 - val_loss: 0.3996\n",
      "Epoch 7/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.3818 - val_loss: 0.3519\n",
      "Epoch 8/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.3437 - val_loss: 0.3130\n",
      "Epoch 9/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.3064 - val_loss: 0.2798\n",
      "Epoch 10/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.2812 - val_loss: 0.2546\n",
      "Epoch 11/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.2589 - val_loss: 0.2321\n",
      "Epoch 12/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.2363 - val_loss: 0.2181\n",
      "Epoch 13/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.2206 - val_loss: 0.1997\n",
      "Epoch 14/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.2067 - val_loss: 0.1866\n",
      "Epoch 15/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.1944 - val_loss: 0.1778\n",
      "Epoch 16/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.1863 - val_loss: 0.1677\n",
      "Epoch 17/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.1760 - val_loss: 0.1602\n",
      "Epoch 18/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.1644 - val_loss: 0.1536\n",
      "Epoch 19/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.1567 - val_loss: 0.1505\n",
      "Epoch 20/600\n",
      "426/426 [==============================] - 0s 117us/sample - loss: 0.1493 - val_loss: 0.1441\n",
      "Epoch 21/600\n",
      "426/426 [==============================] - 0s 138us/sample - loss: 0.1407 - val_loss: 0.1412\n",
      "Epoch 22/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.1328 - val_loss: 0.1347\n",
      "Epoch 23/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.1272 - val_loss: 0.1351\n",
      "Epoch 24/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.1247 - val_loss: 0.1267\n",
      "Epoch 25/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.1194 - val_loss: 0.1319\n",
      "Epoch 26/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.1190 - val_loss: 0.1230\n",
      "Epoch 27/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.1086 - val_loss: 0.1281\n",
      "Epoch 28/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.1048 - val_loss: 0.1179\n",
      "Epoch 29/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.1074 - val_loss: 0.1289\n",
      "Epoch 30/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0968 - val_loss: 0.1158\n",
      "Epoch 31/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0928 - val_loss: 0.1173\n",
      "Epoch 32/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0884 - val_loss: 0.1176\n",
      "Epoch 33/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0907 - val_loss: 0.1123\n",
      "Epoch 34/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0862 - val_loss: 0.1184\n",
      "Epoch 35/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0823 - val_loss: 0.1153\n",
      "Epoch 36/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0790 - val_loss: 0.1110\n",
      "Epoch 37/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0779 - val_loss: 0.1127\n",
      "Epoch 38/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0757 - val_loss: 0.1131\n",
      "Epoch 39/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0743 - val_loss: 0.1101\n",
      "Epoch 40/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0721 - val_loss: 0.1103\n",
      "Epoch 41/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.0733 - val_loss: 0.1119\n",
      "Epoch 42/600\n",
      "426/426 [==============================] - 0s 220us/sample - loss: 0.0736 - val_loss: 0.1098\n",
      "Epoch 43/600\n",
      "426/426 [==============================] - 0s 208us/sample - loss: 0.0706 - val_loss: 0.1099\n",
      "Epoch 44/600\n",
      "426/426 [==============================] - 0s 225us/sample - loss: 0.0675 - val_loss: 0.1104\n",
      "Epoch 45/600\n",
      "426/426 [==============================] - 0s 159us/sample - loss: 0.0671 - val_loss: 0.1082\n",
      "Epoch 46/600\n",
      "426/426 [==============================] - 0s 150us/sample - loss: 0.0672 - val_loss: 0.1152\n",
      "Epoch 47/600\n",
      "426/426 [==============================] - 0s 145us/sample - loss: 0.0664 - val_loss: 0.1115\n",
      "Epoch 48/600\n",
      "426/426 [==============================] - 0s 192us/sample - loss: 0.0662 - val_loss: 0.1116\n",
      "Epoch 49/600\n",
      "426/426 [==============================] - 0s 232us/sample - loss: 0.0667 - val_loss: 0.1109\n",
      "Epoch 50/600\n",
      "426/426 [==============================] - 0s 171us/sample - loss: 0.0635 - val_loss: 0.1117\n",
      "Epoch 51/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0616 - val_loss: 0.1165\n",
      "Epoch 52/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0626 - val_loss: 0.1094\n",
      "Epoch 53/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.0606 - val_loss: 0.1143\n",
      "Epoch 54/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.0624 - val_loss: 0.1133\n",
      "Epoch 55/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0618 - val_loss: 0.1187\n",
      "Epoch 56/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0605 - val_loss: 0.1086\n",
      "Epoch 57/600\n",
      "426/426 [==============================] - 0s 157us/sample - loss: 0.0580 - val_loss: 0.1129\n",
      "Epoch 58/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.0586 - val_loss: 0.1124\n",
      "Epoch 59/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0565 - val_loss: 0.1068\n",
      "Epoch 60/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0574 - val_loss: 0.1186\n",
      "Epoch 61/600\n",
      "426/426 [==============================] - 0s 145us/sample - loss: 0.0573 - val_loss: 0.1077\n",
      "Epoch 62/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0563 - val_loss: 0.1094\n",
      "Epoch 63/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0554 - val_loss: 0.1173\n",
      "Epoch 64/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0563 - val_loss: 0.1105\n",
      "Epoch 65/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0538 - val_loss: 0.1136\n",
      "Epoch 66/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0546 - val_loss: 0.1104\n",
      "Epoch 67/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0533 - val_loss: 0.1153\n",
      "Epoch 68/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0576 - val_loss: 0.1157\n",
      "Epoch 69/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0540 - val_loss: 0.1133\n",
      "Epoch 70/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0528 - val_loss: 0.1132\n",
      "Epoch 71/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0542 - val_loss: 0.1123\n",
      "Epoch 72/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0548 - val_loss: 0.1118\n",
      "Epoch 73/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0512 - val_loss: 0.1197\n",
      "Epoch 74/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0511 - val_loss: 0.1107\n",
      "Epoch 75/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0511 - val_loss: 0.1170\n",
      "Epoch 76/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0508 - val_loss: 0.1138\n",
      "Epoch 77/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0504 - val_loss: 0.1139\n",
      "Epoch 78/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0505 - val_loss: 0.1180\n",
      "Epoch 79/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0512 - val_loss: 0.1151\n",
      "Epoch 80/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0502 - val_loss: 0.1180\n",
      "Epoch 81/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0501 - val_loss: 0.1144\n",
      "Epoch 82/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0536 - val_loss: 0.1223\n",
      "Epoch 83/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0494 - val_loss: 0.1132\n",
      "Epoch 84/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0487 - val_loss: 0.1219\n",
      "Epoch 85/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0509 - val_loss: 0.1158\n",
      "Epoch 86/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0515 - val_loss: 0.1157\n",
      "Epoch 87/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0495 - val_loss: 0.1166\n",
      "Epoch 88/600\n",
      "426/426 [==============================] - 0s 129us/sample - loss: 0.0498 - val_loss: 0.1143\n",
      "Epoch 89/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0554 - val_loss: 0.1250\n",
      "Epoch 90/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0474 - val_loss: 0.1172\n",
      "Epoch 91/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0496 - val_loss: 0.1232\n",
      "Epoch 92/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0467 - val_loss: 0.1166\n",
      "Epoch 93/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0465 - val_loss: 0.1249\n",
      "Epoch 94/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0466 - val_loss: 0.1202\n",
      "Epoch 95/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0476 - val_loss: 0.1189\n",
      "Epoch 96/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0483 - val_loss: 0.1281\n",
      "Epoch 97/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0506 - val_loss: 0.1191\n",
      "Epoch 98/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0454 - val_loss: 0.1286\n",
      "Epoch 99/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0454 - val_loss: 0.1181\n",
      "Epoch 100/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0459 - val_loss: 0.1216\n",
      "Epoch 101/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0447 - val_loss: 0.1239\n",
      "Epoch 102/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0466 - val_loss: 0.1170\n",
      "Epoch 103/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0473 - val_loss: 0.1245\n",
      "Epoch 104/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0503 - val_loss: 0.1162\n",
      "Epoch 105/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0467 - val_loss: 0.1195\n",
      "Epoch 106/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0474 - val_loss: 0.1238\n",
      "Epoch 107/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0464 - val_loss: 0.1278\n",
      "Epoch 108/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0465 - val_loss: 0.1219\n",
      "Epoch 109/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0446 - val_loss: 0.1291\n",
      "Epoch 110/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0478 - val_loss: 0.1247\n",
      "Epoch 111/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0443 - val_loss: 0.1277\n",
      "Epoch 112/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0456 - val_loss: 0.1234\n",
      "Epoch 113/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0445 - val_loss: 0.1285\n",
      "Epoch 114/600\n",
      "426/426 [==============================] - 0s 131us/sample - loss: 0.0430 - val_loss: 0.1352\n",
      "Epoch 115/600\n",
      "426/426 [==============================] - 0s 147us/sample - loss: 0.0444 - val_loss: 0.1255\n",
      "Epoch 116/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0452 - val_loss: 0.1362\n",
      "Epoch 117/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0450 - val_loss: 0.1256\n",
      "Epoch 118/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0439 - val_loss: 0.1397\n",
      "Epoch 119/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0449 - val_loss: 0.1322\n",
      "Epoch 120/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0426 - val_loss: 0.1241\n",
      "Epoch 121/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0449 - val_loss: 0.1415\n",
      "Epoch 122/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.0450 - val_loss: 0.1235\n",
      "Epoch 123/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0421 - val_loss: 0.1380\n",
      "Epoch 124/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0461 - val_loss: 0.1290\n",
      "Epoch 125/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0443 - val_loss: 0.1392\n",
      "Epoch 126/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0411 - val_loss: 0.1242\n",
      "Epoch 127/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0440 - val_loss: 0.1322\n",
      "Epoch 128/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0431 - val_loss: 0.1323\n",
      "Epoch 129/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0492 - val_loss: 0.1482\n",
      "Epoch 130/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0400 - val_loss: 0.1268\n",
      "Epoch 131/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0406 - val_loss: 0.1335\n",
      "Epoch 132/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0404 - val_loss: 0.1315\n",
      "Epoch 133/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0409 - val_loss: 0.1329\n",
      "Epoch 134/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0402 - val_loss: 0.1351\n",
      "Epoch 135/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0429 - val_loss: 0.1264\n",
      "Epoch 136/600\n",
      "426/426 [==============================] - 0s 150us/sample - loss: 0.0396 - val_loss: 0.1474\n",
      "Epoch 137/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.0388 - val_loss: 0.1272\n",
      "Epoch 138/600\n",
      "426/426 [==============================] - 0s 342us/sample - loss: 0.0431 - val_loss: 0.1425\n",
      "Epoch 139/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.0400 - val_loss: 0.1299\n",
      "Epoch 140/600\n",
      "426/426 [==============================] - 0s 126us/sample - loss: 0.0398 - val_loss: 0.1289\n",
      "Epoch 141/600\n",
      "426/426 [==============================] - 0s 131us/sample - loss: 0.0408 - val_loss: 0.1315\n",
      "Epoch 142/600\n",
      "426/426 [==============================] - 0s 143us/sample - loss: 0.0452 - val_loss: 0.1417\n",
      "Epoch 143/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.0396 - val_loss: 0.1316\n",
      "Epoch 144/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.0401 - val_loss: 0.1359\n",
      "Epoch 145/600\n",
      "426/426 [==============================] - 0s 117us/sample - loss: 0.0449 - val_loss: 0.1445\n",
      "Epoch 146/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0421 - val_loss: 0.1275\n",
      "Epoch 147/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0388 - val_loss: 0.1436\n",
      "Epoch 148/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.018 - 0s 82us/sample - loss: 0.0406 - val_loss: 0.1399\n",
      "Epoch 149/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.0380 - val_loss: 0.1340\n",
      "Epoch 150/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.0388 - val_loss: 0.1384\n",
      "Epoch 151/600\n",
      "426/426 [==============================] - 0s 129us/sample - loss: 0.0386 - val_loss: 0.1352\n",
      "Epoch 152/600\n",
      "426/426 [==============================] - 0s 150us/sample - loss: 0.0393 - val_loss: 0.1411\n",
      "Epoch 153/600\n",
      "426/426 [==============================] - 0s 157us/sample - loss: 0.0375 - val_loss: 0.1364\n",
      "Epoch 154/600\n",
      "426/426 [==============================] - 0s 124us/sample - loss: 0.0384 - val_loss: 0.1347\n",
      "Epoch 155/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0371 - val_loss: 0.1437\n",
      "Epoch 156/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0396 - val_loss: 0.1355\n",
      "Epoch 157/600\n",
      "426/426 [==============================] - 0s 150us/sample - loss: 0.0418 - val_loss: 0.1358\n",
      "Epoch 158/600\n",
      "426/426 [==============================] - 0s 155us/sample - loss: 0.0380 - val_loss: 0.1355\n",
      "Epoch 159/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.0374 - val_loss: 0.1333\n",
      "Epoch 160/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0367 - val_loss: 0.1421\n",
      "Epoch 161/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0365 - val_loss: 0.1415\n",
      "Epoch 162/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0408 - val_loss: 0.1516\n",
      "Epoch 163/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0410 - val_loss: 0.1297\n",
      "Epoch 164/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0386 - val_loss: 0.1441\n",
      "Epoch 165/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0365 - val_loss: 0.1368\n",
      "Epoch 166/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0360 - val_loss: 0.1384\n",
      "Epoch 167/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0423 - val_loss: 0.1536\n",
      "Epoch 168/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0387 - val_loss: 0.1387\n",
      "Epoch 169/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0370 - val_loss: 0.1394\n",
      "Epoch 170/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0358 - val_loss: 0.1481\n",
      "Epoch 171/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0372 - val_loss: 0.1349\n",
      "Epoch 172/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0369 - val_loss: 0.1453\n",
      "Epoch 173/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0366 - val_loss: 0.1325\n",
      "Epoch 174/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0360 - val_loss: 0.1445\n",
      "Epoch 175/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.0378 - val_loss: 0.1454\n",
      "Epoch 176/600\n",
      "426/426 [==============================] - 0s 201us/sample - loss: 0.0355 - val_loss: 0.1445\n",
      "Epoch 177/600\n",
      "426/426 [==============================] - 0s 302us/sample - loss: 0.0383 - val_loss: 0.1377\n",
      "Epoch 178/600\n",
      "426/426 [==============================] - 0s 447us/sample - loss: 0.0440 - val_loss: 0.1471\n",
      "Epoch 179/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.0449 - val_loss: 0.1341\n",
      "Epoch 180/600\n",
      "426/426 [==============================] - 0s 204us/sample - loss: 0.0377 - val_loss: 0.1356\n",
      "Epoch 181/600\n",
      "426/426 [==============================] - 0s 150us/sample - loss: 0.0369 - val_loss: 0.1409\n",
      "Epoch 182/600\n",
      "426/426 [==============================] - 0s 138us/sample - loss: 0.0372 - val_loss: 0.1410\n",
      "Epoch 183/600\n",
      "426/426 [==============================] - 0s 159us/sample - loss: 0.0386 - val_loss: 0.1436\n",
      "Epoch 184/600\n",
      "426/426 [==============================] - 0s 162us/sample - loss: 0.0414 - val_loss: 0.1391\n",
      "Epoch 185/600\n",
      "426/426 [==============================] - 0s 169us/sample - loss: 0.0339 - val_loss: 0.1442\n",
      "Epoch 186/600\n",
      "426/426 [==============================] - 0s 136us/sample - loss: 0.0354 - val_loss: 0.1429\n",
      "Epoch 187/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0345 - val_loss: 0.1423\n",
      "Epoch 188/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.0403 - val_loss: 0.1371\n",
      "Epoch 189/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0341 - val_loss: 0.1434\n",
      "Epoch 190/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0341 - val_loss: 0.1436\n",
      "Epoch 191/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0347 - val_loss: 0.1452\n",
      "Epoch 192/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0357 - val_loss: 0.1404\n",
      "Epoch 193/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0361 - val_loss: 0.1410\n",
      "Epoch 194/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0353 - val_loss: 0.1467\n",
      "Epoch 195/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0368 - val_loss: 0.1397\n",
      "Epoch 196/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0493 - val_loss: 0.1380\n",
      "Epoch 197/600\n",
      "426/426 [==============================] - 0s 117us/sample - loss: 0.0326 - val_loss: 0.1632\n",
      "Epoch 198/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0354 - val_loss: 0.1404\n",
      "Epoch 199/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0340 - val_loss: 0.1532\n",
      "Epoch 200/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0372 - val_loss: 0.1547\n",
      "Epoch 201/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0333 - val_loss: 0.1407\n",
      "Epoch 202/600\n",
      "426/426 [==============================] - 0s 199us/sample - loss: 0.0335 - val_loss: 0.1428\n",
      "Epoch 203/600\n",
      "426/426 [==============================] - 0s 143us/sample - loss: 0.0340 - val_loss: 0.1432\n",
      "Epoch 204/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0371 - val_loss: 0.1401\n",
      "Epoch 205/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0318 - val_loss: 0.1553\n",
      "Epoch 206/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0336 - val_loss: 0.1418\n",
      "Epoch 207/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0327 - val_loss: 0.1454\n",
      "Epoch 208/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0336 - val_loss: 0.1395\n",
      "Epoch 209/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0325 - val_loss: 0.1422\n",
      "Epoch 210/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0325 - val_loss: 0.1468\n",
      "Epoch 211/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0319 - val_loss: 0.1429\n",
      "Epoch 212/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0313 - val_loss: 0.1467\n",
      "Epoch 213/600\n",
      "426/426 [==============================] - 0s 176us/sample - loss: 0.0335 - val_loss: 0.1452\n",
      "Epoch 214/600\n",
      "426/426 [==============================] - 0s 234us/sample - loss: 0.0366 - val_loss: 0.1514\n",
      "Epoch 215/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0340 - val_loss: 0.1409\n",
      "Epoch 216/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.0407 - val_loss: 0.1503\n",
      "Epoch 217/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0323 - val_loss: 0.1384\n",
      "Epoch 218/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0334 - val_loss: 0.1454\n",
      "Epoch 219/600\n",
      "426/426 [==============================] - 0s 136us/sample - loss: 0.0345 - val_loss: 0.1562\n",
      "Epoch 220/600\n",
      "426/426 [==============================] - 0s 194us/sample - loss: 0.0341 - val_loss: 0.1387\n",
      "Epoch 221/600\n",
      "426/426 [==============================] - 0s 126us/sample - loss: 0.0332 - val_loss: 0.1584\n",
      "Epoch 222/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.0339 - val_loss: 0.1469\n",
      "Epoch 223/600\n",
      "426/426 [==============================] - 0s 215us/sample - loss: 0.0336 - val_loss: 0.1391\n",
      "Epoch 224/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.0313 - val_loss: 0.1501\n",
      "Epoch 225/600\n",
      "426/426 [==============================] - 0s 201us/sample - loss: 0.0316 - val_loss: 0.1449\n",
      "Epoch 226/600\n",
      "426/426 [==============================] - 0s 147us/sample - loss: 0.0302 - val_loss: 0.1478\n",
      "Epoch 227/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0308 - val_loss: 0.1551\n",
      "Epoch 228/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0310 - val_loss: 0.1438\n",
      "Epoch 229/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0299 - val_loss: 0.1450\n",
      "Epoch 230/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0300 - val_loss: 0.1465\n",
      "Epoch 231/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0301 - val_loss: 0.1438\n",
      "Epoch 232/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0300 - val_loss: 0.1489\n",
      "Epoch 233/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0314 - val_loss: 0.1431\n",
      "Epoch 234/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0398 - val_loss: 0.1540\n",
      "Epoch 235/600\n",
      "426/426 [==============================] - 0s 199us/sample - loss: 0.0387 - val_loss: 0.1379\n",
      "Epoch 236/600\n",
      "426/426 [==============================] - 0s 136us/sample - loss: 0.0401 - val_loss: 0.1724\n",
      "Epoch 237/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0327 - val_loss: 0.1416\n",
      "Epoch 238/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0307 - val_loss: 0.1443\n",
      "Epoch 239/600\n",
      "426/426 [==============================] - 0s 206us/sample - loss: 0.0291 - val_loss: 0.1548\n",
      "Epoch 240/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0303 - val_loss: 0.1496\n",
      "Epoch 241/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0308 - val_loss: 0.1473\n",
      "Epoch 242/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0323 - val_loss: 0.1472\n",
      "Epoch 243/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0305 - val_loss: 0.1476\n",
      "Epoch 244/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.0295 - val_loss: 0.1517\n",
      "Epoch 245/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0287 - val_loss: 0.1460\n",
      "Epoch 246/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0330 - val_loss: 0.1638\n",
      "Epoch 247/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0302 - val_loss: 0.1452\n",
      "Epoch 248/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.0312 - val_loss: 0.1504\n",
      "Epoch 249/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0315 - val_loss: 0.1470\n",
      "Epoch 250/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0311 - val_loss: 0.1591\n",
      "Epoch 251/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0339 - val_loss: 0.1404\n",
      "Epoch 252/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0332 - val_loss: 0.1573\n",
      "Epoch 253/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0290 - val_loss: 0.1450\n",
      "Epoch 254/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.022 - 0s 108us/sample - loss: 0.0294 - val_loss: 0.1533\n",
      "Epoch 255/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0313 - val_loss: 0.1477\n",
      "Epoch 256/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0359 - val_loss: 0.1535\n",
      "Epoch 257/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0341 - val_loss: 0.1499\n",
      "Epoch 258/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0390 - val_loss: 0.1544\n",
      "Epoch 259/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0287 - val_loss: 0.1437\n",
      "Epoch 260/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0284 - val_loss: 0.1548\n",
      "Epoch 261/600\n",
      "426/426 [==============================] - 0s 187us/sample - loss: 0.0296 - val_loss: 0.1598\n",
      "Epoch 262/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0429 - val_loss: 0.1486\n",
      "Epoch 263/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0338 - val_loss: 0.1481\n",
      "Epoch 264/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0278 - val_loss: 0.1493\n",
      "Epoch 265/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0287 - val_loss: 0.1497\n",
      "Epoch 266/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0369 - val_loss: 0.1558\n",
      "Epoch 267/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0283 - val_loss: 0.1642\n",
      "Epoch 268/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0273 - val_loss: 0.1505\n",
      "Epoch 269/600\n",
      "426/426 [==============================] - 0s 138us/sample - loss: 0.0266 - val_loss: 0.1578\n",
      "Epoch 270/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0292 - val_loss: 0.1541\n",
      "Epoch 271/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0282 - val_loss: 0.1525\n",
      "Epoch 272/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0273 - val_loss: 0.1636\n",
      "Epoch 273/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0327 - val_loss: 0.1445\n",
      "Epoch 274/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0322 - val_loss: 0.1654\n",
      "Epoch 275/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0264 - val_loss: 0.1504\n",
      "Epoch 276/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0286 - val_loss: 0.1526\n",
      "Epoch 277/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0291 - val_loss: 0.1558\n",
      "Epoch 278/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0264 - val_loss: 0.1551\n",
      "Epoch 279/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0251 - val_loss: 0.1498\n",
      "Epoch 280/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0263 - val_loss: 0.1569\n",
      "Epoch 281/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0262 - val_loss: 0.1544\n",
      "Epoch 282/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0271 - val_loss: 0.1514\n",
      "Epoch 283/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0265 - val_loss: 0.1579\n",
      "Epoch 284/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0258 - val_loss: 0.1544\n",
      "Epoch 285/600\n",
      "426/426 [==============================] - 0s 129us/sample - loss: 0.0268 - val_loss: 0.1575\n",
      "Epoch 286/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0264 - val_loss: 0.1506\n",
      "Epoch 287/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0265 - val_loss: 0.1509\n",
      "Epoch 288/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0258 - val_loss: 0.1541\n",
      "Epoch 289/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0298 - val_loss: 0.1699\n",
      "Epoch 290/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0264 - val_loss: 0.1547\n",
      "Epoch 291/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0260 - val_loss: 0.1700\n",
      "Epoch 292/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.0255 - val_loss: 0.1509\n",
      "Epoch 293/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0261 - val_loss: 0.1663\n",
      "Epoch 294/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0247 - val_loss: 0.1509\n",
      "Epoch 295/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0249 - val_loss: 0.1585\n",
      "Epoch 296/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0246 - val_loss: 0.1536\n",
      "Epoch 297/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0249 - val_loss: 0.1600\n",
      "Epoch 298/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0241 - val_loss: 0.1537\n",
      "Epoch 299/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0263 - val_loss: 0.1537\n",
      "Epoch 300/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0265 - val_loss: 0.1599\n",
      "Epoch 301/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0309 - val_loss: 0.1801\n",
      "Epoch 302/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0316 - val_loss: 0.1492\n",
      "Epoch 303/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0350 - val_loss: 0.1685\n",
      "Epoch 304/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0256 - val_loss: 0.1590\n",
      "Epoch 305/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0244 - val_loss: 0.1564\n",
      "Epoch 306/600\n",
      "426/426 [==============================] - 0s 117us/sample - loss: 0.0247 - val_loss: 0.1566\n",
      "Epoch 307/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.0256 - val_loss: 0.1603\n",
      "Epoch 308/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.0235 - val_loss: 0.1640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0250 - val_loss: 0.1539\n",
      "Epoch 310/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0242 - val_loss: 0.1606\n",
      "Epoch 311/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0250 - val_loss: 0.1552\n",
      "Epoch 312/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0370 - val_loss: 0.1587\n",
      "Epoch 313/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0254 - val_loss: 0.1640\n",
      "Epoch 314/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0241 - val_loss: 0.1554\n",
      "Epoch 315/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0241 - val_loss: 0.1637\n",
      "Epoch 316/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0239 - val_loss: 0.1543\n",
      "Epoch 317/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0245 - val_loss: 0.1557\n",
      "Epoch 318/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0261 - val_loss: 0.1640\n",
      "Epoch 319/600\n",
      "426/426 [==============================] - 0s 145us/sample - loss: 0.0270 - val_loss: 0.1625\n",
      "Epoch 320/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0261 - val_loss: 0.1602\n",
      "Epoch 321/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0230 - val_loss: 0.1671\n",
      "Epoch 322/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0246 - val_loss: 0.1645\n",
      "Epoch 323/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0265 - val_loss: 0.1668\n",
      "Epoch 324/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0254 - val_loss: 0.1842\n",
      "Epoch 325/600\n",
      "426/426 [==============================] - 0s 155us/sample - loss: 0.0259 - val_loss: 0.1584\n",
      "Epoch 326/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.0260 - val_loss: 0.1615\n",
      "Epoch 327/600\n",
      "426/426 [==============================] - 0s 117us/sample - loss: 0.0271 - val_loss: 0.1701\n",
      "Epoch 328/600\n",
      "426/426 [==============================] - 0s 178us/sample - loss: 0.0242 - val_loss: 0.1668\n",
      "Epoch 329/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0231 - val_loss: 0.1548\n",
      "Epoch 330/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0258 - val_loss: 0.1739\n",
      "Epoch 331/600\n",
      "426/426 [==============================] - 0s 152us/sample - loss: 0.0250 - val_loss: 0.1632\n",
      "Epoch 332/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0222 - val_loss: 0.1633\n",
      "Epoch 333/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0222 - val_loss: 0.1656\n",
      "Epoch 334/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0231 - val_loss: 0.1581\n",
      "Epoch 335/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.0237 - val_loss: 0.1675\n",
      "Epoch 336/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0221 - val_loss: 0.1597\n",
      "Epoch 337/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.0258 - val_loss: 0.1751\n",
      "Epoch 338/600\n",
      "426/426 [==============================] - 0s 157us/sample - loss: 0.0231 - val_loss: 0.1634\n",
      "Epoch 339/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0240 - val_loss: 0.1634\n",
      "Epoch 340/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0228 - val_loss: 0.1723\n",
      "Epoch 341/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0209 - val_loss: 0.1613\n",
      "Epoch 342/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0222 - val_loss: 0.1689\n",
      "Epoch 343/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.0217 - val_loss: 0.1599\n",
      "Epoch 344/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.0208 - val_loss: 0.1775\n",
      "Epoch 345/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0235 - val_loss: 0.1659\n",
      "Epoch 346/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0215 - val_loss: 0.1717\n",
      "Epoch 347/600\n",
      "426/426 [==============================] - 0s 136us/sample - loss: 0.0209 - val_loss: 0.1641\n",
      "Epoch 348/600\n",
      "426/426 [==============================] - 0s 138us/sample - loss: 0.0248 - val_loss: 0.1884\n",
      "Epoch 349/600\n",
      "426/426 [==============================] - 0s 166us/sample - loss: 0.0238 - val_loss: 0.1731\n",
      "Epoch 350/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.0208 - val_loss: 0.1688\n",
      "Epoch 351/600\n",
      "426/426 [==============================] - 0s 143us/sample - loss: 0.0211 - val_loss: 0.1822\n",
      "Epoch 352/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0222 - val_loss: 0.1742\n",
      "Epoch 353/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0246 - val_loss: 0.1620\n",
      "Epoch 354/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.0258 - val_loss: 0.1947\n",
      "Epoch 355/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0247 - val_loss: 0.1646\n",
      "Epoch 356/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0223 - val_loss: 0.1768\n",
      "Epoch 357/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0227 - val_loss: 0.1692\n",
      "Epoch 358/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0211 - val_loss: 0.1759\n",
      "Epoch 359/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0208 - val_loss: 0.1629\n",
      "Epoch 360/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0229 - val_loss: 0.1649\n",
      "Epoch 361/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0223 - val_loss: 0.1787\n",
      "Epoch 362/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0198 - val_loss: 0.1637\n",
      "Epoch 363/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0204 - val_loss: 0.1739\n",
      "Epoch 364/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0207 - val_loss: 0.1682\n",
      "Epoch 365/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0208 - val_loss: 0.1653\n",
      "Epoch 366/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0236 - val_loss: 0.1818\n",
      "Epoch 367/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0201 - val_loss: 0.1730\n",
      "Epoch 368/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0207 - val_loss: 0.1731\n",
      "Epoch 369/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0198 - val_loss: 0.1789\n",
      "Epoch 370/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0196 - val_loss: 0.1666\n",
      "Epoch 371/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0213 - val_loss: 0.1838\n",
      "Epoch 372/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0196 - val_loss: 0.1697\n",
      "Epoch 373/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0216 - val_loss: 0.1662\n",
      "Epoch 374/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0214 - val_loss: 0.1979\n",
      "Epoch 375/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0285 - val_loss: 0.1625\n",
      "Epoch 376/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0244 - val_loss: 0.1973\n",
      "Epoch 377/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0207 - val_loss: 0.1656\n",
      "Epoch 378/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0362 - val_loss: 0.2197\n",
      "Epoch 379/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0200 - val_loss: 0.1635\n",
      "Epoch 380/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0231 - val_loss: 0.2011\n",
      "Epoch 381/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0210 - val_loss: 0.1719\n",
      "Epoch 382/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0203 - val_loss: 0.1725\n",
      "Epoch 383/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0213 - val_loss: 0.1736\n",
      "Epoch 384/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0194 - val_loss: 0.1829\n",
      "Epoch 385/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0196 - val_loss: 0.1737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0190 - val_loss: 0.1873\n",
      "Epoch 387/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0200 - val_loss: 0.1669\n",
      "Epoch 388/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0210 - val_loss: 0.1775\n",
      "Epoch 389/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0210 - val_loss: 0.1763\n",
      "Epoch 390/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0211 - val_loss: 0.2009\n",
      "Epoch 391/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0243 - val_loss: 0.1705\n",
      "Epoch 392/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0233 - val_loss: 0.2106\n",
      "Epoch 393/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0197 - val_loss: 0.1707\n",
      "Epoch 394/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0221 - val_loss: 0.1865\n",
      "Epoch 395/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0261 - val_loss: 0.1681\n",
      "Epoch 396/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0230 - val_loss: 0.2066\n",
      "Epoch 397/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0199 - val_loss: 0.1692\n",
      "Epoch 398/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0181 - val_loss: 0.1950\n",
      "Epoch 399/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0213 - val_loss: 0.1684\n",
      "Epoch 400/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0212 - val_loss: 0.1921\n",
      "Epoch 401/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0234 - val_loss: 0.1720\n",
      "Epoch 402/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0217 - val_loss: 0.2045\n",
      "Epoch 403/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0201 - val_loss: 0.1716\n",
      "Epoch 404/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0178 - val_loss: 0.1881\n",
      "Epoch 405/600\n",
      "426/426 [==============================] - 0s 124us/sample - loss: 0.0201 - val_loss: 0.1769\n",
      "Epoch 406/600\n",
      "426/426 [==============================] - 0s 302us/sample - loss: 0.0238 - val_loss: 0.1832\n",
      "Epoch 407/600\n",
      "426/426 [==============================] - 0s 117us/sample - loss: 0.0215 - val_loss: 0.1850\n",
      "Epoch 408/600\n",
      "426/426 [==============================] - 0s 136us/sample - loss: 0.0178 - val_loss: 0.1848\n",
      "Epoch 409/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0184 - val_loss: 0.1884\n",
      "Epoch 410/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0176 - val_loss: 0.1856\n",
      "Epoch 411/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0178 - val_loss: 0.1925\n",
      "Epoch 412/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0189 - val_loss: 0.1910\n",
      "Epoch 413/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0234 - val_loss: 0.1949\n",
      "Epoch 414/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0184 - val_loss: 0.1817\n",
      "Epoch 415/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0170 - val_loss: 0.1959\n",
      "Epoch 416/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0169 - val_loss: 0.1797\n",
      "Epoch 417/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0230 - val_loss: 0.1990\n",
      "Epoch 418/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0185 - val_loss: 0.1846\n",
      "Epoch 419/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.011 - 0s 77us/sample - loss: 0.0182 - val_loss: 0.1802\n",
      "Epoch 420/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0200 - val_loss: 0.1852\n",
      "Epoch 421/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0222 - val_loss: 0.2374\n",
      "Epoch 422/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0220 - val_loss: 0.1737\n",
      "Epoch 423/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0198 - val_loss: 0.1923\n",
      "Epoch 424/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0170 - val_loss: 0.1903\n",
      "Epoch 425/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0184 - val_loss: 0.1830\n",
      "Epoch 426/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0199 - val_loss: 0.1753\n",
      "Epoch 427/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0179 - val_loss: 0.1892\n",
      "Epoch 428/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0168 - val_loss: 0.1796\n",
      "Epoch 429/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0175 - val_loss: 0.1860\n",
      "Epoch 430/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0159 - val_loss: 0.1848\n",
      "Epoch 431/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0159 - val_loss: 0.1871\n",
      "Epoch 432/600\n",
      "426/426 [==============================] - 0s 234us/sample - loss: 0.0169 - val_loss: 0.1959\n",
      "Epoch 433/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.0168 - val_loss: 0.1826\n",
      "Epoch 434/600\n",
      "426/426 [==============================] - 0s 129us/sample - loss: 0.0163 - val_loss: 0.1893\n",
      "Epoch 435/600\n",
      "426/426 [==============================] - 0s 129us/sample - loss: 0.0159 - val_loss: 0.1969\n",
      "Epoch 436/600\n",
      "426/426 [==============================] - 0s 117us/sample - loss: 0.0193 - val_loss: 0.1823\n",
      "Epoch 437/600\n",
      "426/426 [==============================] - 0s 124us/sample - loss: 0.0164 - val_loss: 0.1954\n",
      "Epoch 438/600\n",
      "426/426 [==============================] - 0s 131us/sample - loss: 0.0187 - val_loss: 0.1905\n",
      "Epoch 439/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.0158 - val_loss: 0.2140\n",
      "Epoch 440/600\n",
      "426/426 [==============================] - 0s 131us/sample - loss: 0.0166 - val_loss: 0.1962\n",
      "Epoch 441/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0155 - val_loss: 0.1934\n",
      "Epoch 442/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0182 - val_loss: 0.2027\n",
      "Epoch 443/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0159 - val_loss: 0.1947\n",
      "Epoch 444/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0162 - val_loss: 0.1833\n",
      "Epoch 445/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0154 - val_loss: 0.2067\n",
      "Epoch 446/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0170 - val_loss: 0.1878\n",
      "Epoch 447/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0203 - val_loss: 0.1853\n",
      "Epoch 448/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0160 - val_loss: 0.2162\n",
      "Epoch 449/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0185 - val_loss: 0.1825\n",
      "Epoch 450/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0188 - val_loss: 0.2187\n",
      "Epoch 451/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0176 - val_loss: 0.2001\n",
      "Epoch 452/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0148 - val_loss: 0.1918\n",
      "Epoch 453/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0166 - val_loss: 0.1922\n",
      "Epoch 454/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0168 - val_loss: 0.2135\n",
      "Epoch 455/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.0173 - val_loss: 0.1840\n",
      "Epoch 456/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0167 - val_loss: 0.2233\n",
      "Epoch 457/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0186 - val_loss: 0.1898\n",
      "Epoch 458/600\n",
      "426/426 [==============================] - 0s 145us/sample - loss: 0.0154 - val_loss: 0.2076\n",
      "Epoch 459/600\n",
      "426/426 [==============================] - 0s 129us/sample - loss: 0.0149 - val_loss: 0.1894\n",
      "Epoch 460/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.0165 - val_loss: 0.2143\n",
      "Epoch 461/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0154 - val_loss: 0.1980\n",
      "Epoch 462/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0150 - val_loss: 0.1893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0157 - val_loss: 0.2221\n",
      "Epoch 464/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0152 - val_loss: 0.1910\n",
      "Epoch 465/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0249 - val_loss: 0.2642\n",
      "Epoch 466/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0186 - val_loss: 0.1913\n",
      "Epoch 467/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0161 - val_loss: 0.2234\n",
      "Epoch 468/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0161 - val_loss: 0.1871\n",
      "Epoch 469/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0188 - val_loss: 0.2166\n",
      "Epoch 470/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0151 - val_loss: 0.1907\n",
      "Epoch 471/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0155 - val_loss: 0.2043\n",
      "Epoch 472/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0151 - val_loss: 0.1986\n",
      "Epoch 473/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0157 - val_loss: 0.2043\n",
      "Epoch 474/600\n",
      "426/426 [==============================] - 0s 138us/sample - loss: 0.0192 - val_loss: 0.1917\n",
      "Epoch 475/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0156 - val_loss: 0.2128\n",
      "Epoch 476/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0146 - val_loss: 0.2038\n",
      "Epoch 477/600\n",
      "426/426 [==============================] - 0s 159us/sample - loss: 0.0200 - val_loss: 0.1907\n",
      "Epoch 478/600\n",
      "426/426 [==============================] - 0s 157us/sample - loss: 0.0289 - val_loss: 0.3191\n",
      "Epoch 479/600\n",
      "426/426 [==============================] - 0s 143us/sample - loss: 0.0410 - val_loss: 0.1894\n",
      "Epoch 480/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.0134 - val_loss: 0.2433\n",
      "Epoch 481/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.0176 - val_loss: 0.1894\n",
      "Epoch 482/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0151 - val_loss: 0.2168\n",
      "Epoch 483/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0158 - val_loss: 0.1961\n",
      "Epoch 484/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0191 - val_loss: 0.1982\n",
      "Epoch 485/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0151 - val_loss: 0.2028\n",
      "Epoch 486/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0140 - val_loss: 0.1931\n",
      "Epoch 487/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0150 - val_loss: 0.2102\n",
      "Epoch 488/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0138 - val_loss: 0.2087\n",
      "Epoch 489/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0186 - val_loss: 0.1921\n",
      "Epoch 490/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0175 - val_loss: 0.2235\n",
      "Epoch 491/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0169 - val_loss: 0.2058\n",
      "Epoch 492/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0145 - val_loss: 0.2058\n",
      "Epoch 493/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0134 - val_loss: 0.2064\n",
      "Epoch 494/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0137 - val_loss: 0.2174\n",
      "Epoch 495/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0134 - val_loss: 0.2049\n",
      "Epoch 496/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0127 - val_loss: 0.2220\n",
      "Epoch 497/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0135 - val_loss: 0.1967\n",
      "Epoch 498/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0126 - val_loss: 0.2317\n",
      "Epoch 499/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0136 - val_loss: 0.2104\n",
      "Epoch 500/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0172 - val_loss: 0.2223\n",
      "Epoch 501/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0174 - val_loss: 0.2080\n",
      "Epoch 502/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0143 - val_loss: 0.2244\n",
      "Epoch 503/600\n",
      "426/426 [==============================] - 0s 241us/sample - loss: 0.0142 - val_loss: 0.2095\n",
      "Epoch 504/600\n",
      "426/426 [==============================] - 0s 124us/sample - loss: 0.0199 - val_loss: 0.2013\n",
      "Epoch 505/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0174 - val_loss: 0.2297\n",
      "Epoch 506/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0160 - val_loss: 0.2031\n",
      "Epoch 507/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0183 - val_loss: 0.2180\n",
      "Epoch 508/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0144 - val_loss: 0.2065\n",
      "Epoch 509/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.0140 - val_loss: 0.2107\n",
      "Epoch 510/600\n",
      "426/426 [==============================] - 0s 136us/sample - loss: 0.0126 - val_loss: 0.2128\n",
      "Epoch 511/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0134 - val_loss: 0.2172\n",
      "Epoch 512/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0131 - val_loss: 0.2155\n",
      "Epoch 513/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0122 - val_loss: 0.2120\n",
      "Epoch 514/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0148 - val_loss: 0.2347\n",
      "Epoch 515/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0146 - val_loss: 0.2045\n",
      "Epoch 516/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0129 - val_loss: 0.2264\n",
      "Epoch 517/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0135 - val_loss: 0.2012\n",
      "Epoch 518/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0124 - val_loss: 0.2261\n",
      "Epoch 519/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0119 - val_loss: 0.2123\n",
      "Epoch 520/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0122 - val_loss: 0.2171\n",
      "Epoch 521/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0120 - val_loss: 0.2158\n",
      "Epoch 522/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0136 - val_loss: 0.2417\n",
      "Epoch 523/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0134 - val_loss: 0.2028\n",
      "Epoch 524/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0161 - val_loss: 0.2847\n",
      "Epoch 525/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0164 - val_loss: 0.2062\n",
      "Epoch 526/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0134 - val_loss: 0.2428\n",
      "Epoch 527/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0137 - val_loss: 0.2086\n",
      "Epoch 528/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0153 - val_loss: 0.2388\n",
      "Epoch 529/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0114 - val_loss: 0.2083\n",
      "Epoch 530/600\n",
      "426/426 [==============================] - 0s 129us/sample - loss: 0.0133 - val_loss: 0.2171\n",
      "Epoch 531/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0114 - val_loss: 0.2190\n",
      "Epoch 532/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0123 - val_loss: 0.2169\n",
      "Epoch 533/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0154 - val_loss: 0.2334\n",
      "Epoch 534/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0152 - val_loss: 0.2133\n",
      "Epoch 535/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0126 - val_loss: 0.2447\n",
      "Epoch 536/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0132 - val_loss: 0.2126\n",
      "Epoch 537/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0119 - val_loss: 0.2281\n",
      "Epoch 538/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0128 - val_loss: 0.2156\n",
      "Epoch 539/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0128 - val_loss: 0.2365\n",
      "Epoch 540/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0151 - val_loss: 0.2270\n",
      "Epoch 541/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0127 - val_loss: 0.2197\n",
      "Epoch 542/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0118 - val_loss: 0.2395\n",
      "Epoch 543/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0110 - val_loss: 0.2223\n",
      "Epoch 544/600\n",
      "426/426 [==============================] - 0s 124us/sample - loss: 0.0157 - val_loss: 0.2587\n",
      "Epoch 545/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0148 - val_loss: 0.2216\n",
      "Epoch 546/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0094 - val_loss: 0.2859\n",
      "Epoch 547/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0145 - val_loss: 0.2232\n",
      "Epoch 548/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0118 - val_loss: 0.2658\n",
      "Epoch 549/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0134 - val_loss: 0.2137\n",
      "Epoch 550/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0118 - val_loss: 0.2491\n",
      "Epoch 551/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0137 - val_loss: 0.2250\n",
      "Epoch 552/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0181 - val_loss: 0.2783\n",
      "Epoch 553/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0140 - val_loss: 0.2168\n",
      "Epoch 554/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0125 - val_loss: 0.2558\n",
      "Epoch 555/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0109 - val_loss: 0.2216\n",
      "Epoch 556/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0134 - val_loss: 0.2273\n",
      "Epoch 557/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0164 - val_loss: 0.2800\n",
      "Epoch 558/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0173 - val_loss: 0.2270\n",
      "Epoch 559/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0117 - val_loss: 0.2229\n",
      "Epoch 560/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.0114 - val_loss: 0.2207\n",
      "Epoch 561/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0106 - val_loss: 0.2240\n",
      "Epoch 562/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0106 - val_loss: 0.2434\n",
      "Epoch 563/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0118 - val_loss: 0.2413\n",
      "Epoch 564/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0154 - val_loss: 0.2198\n",
      "Epoch 565/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0098 - val_loss: 0.2432\n",
      "Epoch 566/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0127 - val_loss: 0.2273\n",
      "Epoch 567/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0137 - val_loss: 0.2575\n",
      "Epoch 568/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0105 - val_loss: 0.2211\n",
      "Epoch 569/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0124 - val_loss: 0.2302\n",
      "Epoch 570/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0110 - val_loss: 0.2510\n",
      "Epoch 571/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0099 - val_loss: 0.2349\n",
      "Epoch 572/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0096 - val_loss: 0.2325\n",
      "Epoch 573/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0095 - val_loss: 0.2436\n",
      "Epoch 574/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0102 - val_loss: 0.2375\n",
      "Epoch 575/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0103 - val_loss: 0.2431\n",
      "Epoch 576/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0108 - val_loss: 0.2366\n",
      "Epoch 577/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0118 - val_loss: 0.2607\n",
      "Epoch 578/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0109 - val_loss: 0.2377\n",
      "Epoch 579/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0100 - val_loss: 0.2465\n",
      "Epoch 580/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0096 - val_loss: 0.2426\n",
      "Epoch 581/600\n",
      "426/426 [==============================] - 0s 73us/sample - loss: 0.0124 - val_loss: 0.2369\n",
      "Epoch 582/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0105 - val_loss: 0.2535\n",
      "Epoch 583/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0092 - val_loss: 0.2401\n",
      "Epoch 584/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0107 - val_loss: 0.2742\n",
      "Epoch 585/600\n",
      "426/426 [==============================] - 0s 70us/sample - loss: 0.0128 - val_loss: 0.2402\n",
      "Epoch 586/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0108 - val_loss: 0.2519\n",
      "Epoch 587/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0128 - val_loss: 0.2424\n",
      "Epoch 588/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0106 - val_loss: 0.2537\n",
      "Epoch 589/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0103 - val_loss: 0.2439\n",
      "Epoch 590/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0094 - val_loss: 0.2489\n",
      "Epoch 591/600\n",
      "426/426 [==============================] - 0s 131us/sample - loss: 0.0104 - val_loss: 0.2363\n",
      "Epoch 592/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.2521\n",
      "Epoch 593/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0093 - val_loss: 0.2418\n",
      "Epoch 594/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0097 - val_loss: 0.2419\n",
      "Epoch 595/600\n",
      "426/426 [==============================] - 0s 77us/sample - loss: 0.0158 - val_loss: 0.2655\n",
      "Epoch 596/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0094 - val_loss: 0.2467\n",
      "Epoch 597/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0085 - val_loss: 0.2572\n",
      "Epoch 598/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0089 - val_loss: 0.2483\n",
      "Epoch 599/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.0107 - val_loss: 0.2977\n",
      "Epoch 600/600\n",
      "426/426 [==============================] - 0s 80us/sample - loss: 0.0143 - val_loss: 0.2452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19c67675ef0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=600, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19c61077940>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss.plot() #overfitted the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping Callback\n",
    "\n",
    "lets try again but using callbacks to stop before we overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid')) # 0 or 1\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25) #minimize validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/600\n",
      "426/426 [==============================] - 1s 1ms/sample - loss: 0.6718 - val_loss: 0.6480\n",
      "Epoch 2/600\n",
      "426/426 [==============================] - 0s 118us/sample - loss: 0.6311 - val_loss: 0.6011\n",
      "Epoch 3/600\n",
      "426/426 [==============================] - 0s 113us/sample - loss: 0.5803 - val_loss: 0.5494\n",
      "Epoch 4/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.5299 - val_loss: 0.4980\n",
      "Epoch 5/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.4803 - val_loss: 0.4472\n",
      "Epoch 6/600\n",
      "426/426 [==============================] - 0s 114us/sample - loss: 0.4317 - val_loss: 0.3975\n",
      "Epoch 7/600\n",
      "426/426 [==============================] - 0s 111us/sample - loss: 0.3864 - val_loss: 0.3527\n",
      "Epoch 8/600\n",
      "426/426 [==============================] - 0s 117us/sample - loss: 0.3438 - val_loss: 0.3148\n",
      "Epoch 9/600\n",
      "426/426 [==============================] - 0s 120us/sample - loss: 0.3086 - val_loss: 0.2812\n",
      "Epoch 10/600\n",
      "426/426 [==============================] - 0s 114us/sample - loss: 0.2793 - val_loss: 0.2559\n",
      "Epoch 11/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.2567 - val_loss: 0.2331\n",
      "Epoch 12/600\n",
      "426/426 [==============================] - 0s 95us/sample - loss: 0.2337 - val_loss: 0.2159\n",
      "Epoch 13/600\n",
      "426/426 [==============================] - 0s 111us/sample - loss: 0.2164 - val_loss: 0.2005\n",
      "Epoch 14/600\n",
      "426/426 [==============================] - 0s 150us/sample - loss: 0.2013 - val_loss: 0.1897\n",
      "Epoch 15/600\n",
      "426/426 [==============================] - 0s 113us/sample - loss: 0.1889 - val_loss: 0.1769\n",
      "Epoch 16/600\n",
      "426/426 [==============================] - 0s 113us/sample - loss: 0.1768 - val_loss: 0.1692\n",
      "Epoch 17/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.1657 - val_loss: 0.1624\n",
      "Epoch 18/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.1567 - val_loss: 0.1566\n",
      "Epoch 19/600\n",
      "426/426 [==============================] - 0s 118us/sample - loss: 0.1473 - val_loss: 0.1494\n",
      "Epoch 20/600\n",
      "426/426 [==============================] - 0s 114us/sample - loss: 0.1416 - val_loss: 0.1493\n",
      "Epoch 21/600\n",
      "426/426 [==============================] - 0s 121us/sample - loss: 0.1420 - val_loss: 0.1438\n",
      "Epoch 22/600\n",
      "426/426 [==============================] - 0s 212us/sample - loss: 0.1397 - val_loss: 0.1421\n",
      "Epoch 23/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.1317 - val_loss: 0.1358\n",
      "Epoch 24/600\n",
      "426/426 [==============================] - 0s 126us/sample - loss: 0.1194 - val_loss: 0.1357\n",
      "Epoch 25/600\n",
      "426/426 [==============================] - 0s 156us/sample - loss: 0.1137 - val_loss: 0.1309\n",
      "Epoch 26/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.1093 - val_loss: 0.1327\n",
      "Epoch 27/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.1054 - val_loss: 0.1269\n",
      "Epoch 28/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.1012 - val_loss: 0.1289\n",
      "Epoch 29/600\n",
      "426/426 [==============================] - 0s 104us/sample - loss: 0.1008 - val_loss: 0.1265\n",
      "Epoch 30/600\n",
      "426/426 [==============================] - 0s 137us/sample - loss: 0.0947 - val_loss: 0.1223\n",
      "Epoch 31/600\n",
      "426/426 [==============================] - 0s 189us/sample - loss: 0.0924 - val_loss: 0.1263\n",
      "Epoch 32/600\n",
      "426/426 [==============================] - 0s 167us/sample - loss: 0.0892 - val_loss: 0.1224\n",
      "Epoch 33/600\n",
      "426/426 [==============================] - 0s 123us/sample - loss: 0.0878 - val_loss: 0.1209\n",
      "Epoch 34/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.0849 - val_loss: 0.1221\n",
      "Epoch 35/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0856 - val_loss: 0.1191\n",
      "Epoch 36/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.0829 - val_loss: 0.1208\n",
      "Epoch 37/600\n",
      "426/426 [==============================] - 0s 147us/sample - loss: 0.0788 - val_loss: 0.1204\n",
      "Epoch 38/600\n",
      "426/426 [==============================] - 0s 131us/sample - loss: 0.0786 - val_loss: 0.1190\n",
      "Epoch 39/600\n",
      "426/426 [==============================] - 0s 142us/sample - loss: 0.0763 - val_loss: 0.1215\n",
      "Epoch 40/600\n",
      "426/426 [==============================] - 0s 254us/sample - loss: 0.0758 - val_loss: 0.1241\n",
      "Epoch 41/600\n",
      "426/426 [==============================] - 0s 123us/sample - loss: 0.0751 - val_loss: 0.1186\n",
      "Epoch 42/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0737 - val_loss: 0.1183\n",
      "Epoch 43/600\n",
      "426/426 [==============================] - 0s 109us/sample - loss: 0.0713 - val_loss: 0.1174\n",
      "Epoch 44/600\n",
      "426/426 [==============================] - 0s 135us/sample - loss: 0.0696 - val_loss: 0.1237\n",
      "Epoch 45/600\n",
      "426/426 [==============================] - 0s 155us/sample - loss: 0.0731 - val_loss: 0.1166\n",
      "Epoch 46/600\n",
      "426/426 [==============================] - 0s 141us/sample - loss: 0.0675 - val_loss: 0.1248\n",
      "Epoch 47/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.0679 - val_loss: 0.1196\n",
      "Epoch 48/600\n",
      "426/426 [==============================] - 0s 120us/sample - loss: 0.0665 - val_loss: 0.1216\n",
      "Epoch 49/600\n",
      "426/426 [==============================] - 0s 143us/sample - loss: 0.0649 - val_loss: 0.1184\n",
      "Epoch 50/600\n",
      "426/426 [==============================] - 0s 131us/sample - loss: 0.0648 - val_loss: 0.1200\n",
      "Epoch 51/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.0644 - val_loss: 0.1191\n",
      "Epoch 52/600\n",
      "426/426 [==============================] - 0s 138us/sample - loss: 0.0652 - val_loss: 0.1231\n",
      "Epoch 53/600\n",
      "426/426 [==============================] - 0s 169us/sample - loss: 0.0638 - val_loss: 0.1184\n",
      "Epoch 54/600\n",
      "426/426 [==============================] - 0s 155us/sample - loss: 0.0630 - val_loss: 0.1235\n",
      "Epoch 55/600\n",
      "426/426 [==============================] - 0s 130us/sample - loss: 0.0655 - val_loss: 0.1194\n",
      "Epoch 56/600\n",
      "426/426 [==============================] - 0s 95us/sample - loss: 0.0614 - val_loss: 0.1189\n",
      "Epoch 57/600\n",
      "426/426 [==============================] - 0s 111us/sample - loss: 0.0607 - val_loss: 0.1210\n",
      "Epoch 58/600\n",
      "426/426 [==============================] - 0s 178us/sample - loss: 0.0595 - val_loss: 0.1187\n",
      "Epoch 59/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0596 - val_loss: 0.1217\n",
      "Epoch 60/600\n",
      "426/426 [==============================] - 0s 92us/sample - loss: 0.0584 - val_loss: 0.1198\n",
      "Epoch 61/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.0586 - val_loss: 0.1173\n",
      "Epoch 62/600\n",
      "426/426 [==============================] - 0s 104us/sample - loss: 0.0609 - val_loss: 0.1209\n",
      "Epoch 63/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0584 - val_loss: 0.1199\n",
      "Epoch 64/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.0576 - val_loss: 0.1264\n",
      "Epoch 65/600\n",
      "426/426 [==============================] - 0s 107us/sample - loss: 0.0561 - val_loss: 0.1191\n",
      "Epoch 66/600\n",
      "426/426 [==============================] - 0s 95us/sample - loss: 0.0567 - val_loss: 0.1222\n",
      "Epoch 67/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0564 - val_loss: 0.1200\n",
      "Epoch 68/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0562 - val_loss: 0.1226\n",
      "Epoch 69/600\n",
      "426/426 [==============================] - 0s 153us/sample - loss: 0.0556 - val_loss: 0.1197\n",
      "Epoch 70/600\n",
      "426/426 [==============================] - 0s 160us/sample - loss: 0.0560 - val_loss: 0.1237\n",
      "Epoch 00070: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19c695fcfd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=600, validation_data=(X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19c6925b550>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history) #much better\n",
    "loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout layers\n",
    "\n",
    "use dropout layers to try and minimise overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid')) # 0 or 1\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/600\n",
      "426/426 [==============================] - 1s 1ms/sample - loss: 0.6904 - val_loss: 0.6773\n",
      "Epoch 2/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.6919 - val_loss: 0.6514\n",
      "Epoch 3/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.6673 - val_loss: 0.6259\n",
      "Epoch 4/600\n",
      "426/426 [==============================] - 0s 145us/sample - loss: 0.6349 - val_loss: 0.6024\n",
      "Epoch 5/600\n",
      "426/426 [==============================] - 0s 145us/sample - loss: 0.6198 - val_loss: 0.5780\n",
      "Epoch 6/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.6127 - val_loss: 0.5532\n",
      "Epoch 7/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.5694 - val_loss: 0.5298\n",
      "Epoch 8/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.5464 - val_loss: 0.5025\n",
      "Epoch 9/600\n",
      "426/426 [==============================] - 0s 124us/sample - loss: 0.5194 - val_loss: 0.4739\n",
      "Epoch 10/600\n",
      "426/426 [==============================] - 0s 169us/sample - loss: 0.5151 - val_loss: 0.4458\n",
      "Epoch 11/600\n",
      "426/426 [==============================] - 0s 124us/sample - loss: 0.5004 - val_loss: 0.4205\n",
      "Epoch 12/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.4830 - val_loss: 0.3984\n",
      "Epoch 13/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.4727 - val_loss: 0.3776\n",
      "Epoch 14/600\n",
      "426/426 [==============================] - 0s 124us/sample - loss: 0.4493 - val_loss: 0.3579\n",
      "Epoch 15/600\n",
      "426/426 [==============================] - 0s 145us/sample - loss: 0.4412 - val_loss: 0.3429\n",
      "Epoch 16/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.4281 - val_loss: 0.3244\n",
      "Epoch 17/600\n",
      "426/426 [==============================] - 0s 124us/sample - loss: 0.4089 - val_loss: 0.3051\n",
      "Epoch 18/600\n",
      "426/426 [==============================] - 0s 117us/sample - loss: 0.3866 - val_loss: 0.2849\n",
      "Epoch 19/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.3699 - val_loss: 0.2729\n",
      "Epoch 20/600\n",
      "426/426 [==============================] - 0s 155us/sample - loss: 0.3343 - val_loss: 0.2521\n",
      "Epoch 21/600\n",
      "426/426 [==============================] - 0s 185us/sample - loss: 0.3637 - val_loss: 0.2399\n",
      "Epoch 22/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.3307 - val_loss: 0.2261\n",
      "Epoch 23/600\n",
      "426/426 [==============================] - 0s 183us/sample - loss: 0.3152 - val_loss: 0.2157\n",
      "Epoch 24/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.2996 - val_loss: 0.2103\n",
      "Epoch 25/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.3296 - val_loss: 0.2001\n",
      "Epoch 26/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.3016 - val_loss: 0.1943\n",
      "Epoch 27/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.2829 - val_loss: 0.1897\n",
      "Epoch 28/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.2816 - val_loss: 0.1781\n",
      "Epoch 29/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.2509 - val_loss: 0.1725\n",
      "Epoch 30/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.2379 - val_loss: 0.1668\n",
      "Epoch 31/600\n",
      "426/426 [==============================] - 0s 126us/sample - loss: 0.2426 - val_loss: 0.1560\n",
      "Epoch 32/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.2493 - val_loss: 0.1532\n",
      "Epoch 33/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.2604 - val_loss: 0.1549\n",
      "Epoch 34/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.2582 - val_loss: 0.1530\n",
      "Epoch 35/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.2320 - val_loss: 0.1457\n",
      "Epoch 36/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.2080 - val_loss: 0.1392\n",
      "Epoch 37/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.2149 - val_loss: 0.1401\n",
      "Epoch 38/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.1975 - val_loss: 0.1312\n",
      "Epoch 39/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.2346 - val_loss: 0.1280\n",
      "Epoch 40/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.2065 - val_loss: 0.1309\n",
      "Epoch 41/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.1993 - val_loss: 0.1308\n",
      "Epoch 42/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.2016 - val_loss: 0.1239\n",
      "Epoch 43/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.1958 - val_loss: 0.1226\n",
      "Epoch 44/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.1859 - val_loss: 0.1199\n",
      "Epoch 45/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.2054 - val_loss: 0.1216\n",
      "Epoch 46/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.2212 - val_loss: 0.1383\n",
      "Epoch 47/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.1932 - val_loss: 0.1208\n",
      "Epoch 48/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.1647 - val_loss: 0.1215\n",
      "Epoch 49/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.2021 - val_loss: 0.1156\n",
      "Epoch 50/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.1839 - val_loss: 0.1140\n",
      "Epoch 51/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.1674 - val_loss: 0.1103\n",
      "Epoch 52/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.1750 - val_loss: 0.1068\n",
      "Epoch 53/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.1894 - val_loss: 0.1081\n",
      "Epoch 54/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.1645 - val_loss: 0.1083\n",
      "Epoch 55/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.1787 - val_loss: 0.1097\n",
      "Epoch 56/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.1703 - val_loss: 0.1107\n",
      "Epoch 57/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.1623 - val_loss: 0.1064\n",
      "Epoch 58/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.1617 - val_loss: 0.1109\n",
      "Epoch 59/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.1615 - val_loss: 0.1056\n",
      "Epoch 60/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.1288 - val_loss: 0.1013\n",
      "Epoch 61/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.1363 - val_loss: 0.0991\n",
      "Epoch 62/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.1590 - val_loss: 0.1000\n",
      "Epoch 63/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.1557 - val_loss: 0.0981\n",
      "Epoch 64/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.1617 - val_loss: 0.0993\n",
      "Epoch 65/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.1457 - val_loss: 0.1064\n",
      "Epoch 66/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.1253 - val_loss: 0.1055\n",
      "Epoch 67/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.1592 - val_loss: 0.0963\n",
      "Epoch 68/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.1483 - val_loss: 0.0984\n",
      "Epoch 69/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.1280 - val_loss: 0.1058\n",
      "Epoch 70/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.1642 - val_loss: 0.0983\n",
      "Epoch 71/600\n",
      "426/426 [==============================] - 0s 138us/sample - loss: 0.1554 - val_loss: 0.0962\n",
      "Epoch 72/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.1410 - val_loss: 0.0965\n",
      "Epoch 73/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.1383 - val_loss: 0.1029\n",
      "Epoch 74/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.1490 - val_loss: 0.0998\n",
      "Epoch 75/600\n",
      "426/426 [==============================] - 0s 124us/sample - loss: 0.1436 - val_loss: 0.0988\n",
      "Epoch 76/600\n",
      "426/426 [==============================] - 0s 117us/sample - loss: 0.1367 - val_loss: 0.1016\n",
      "Epoch 77/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.1194 - val_loss: 0.0947\n",
      "Epoch 78/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 105us/sample - loss: 0.1213 - val_loss: 0.0960\n",
      "Epoch 79/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.1391 - val_loss: 0.0989\n",
      "Epoch 80/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.1082 - val_loss: 0.1100\n",
      "Epoch 81/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.1288 - val_loss: 0.0929\n",
      "Epoch 82/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.1255 - val_loss: 0.1016\n",
      "Epoch 83/600\n",
      "426/426 [==============================] - 0s 82us/sample - loss: 0.1271 - val_loss: 0.1013\n",
      "Epoch 84/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.1307 - val_loss: 0.0912\n",
      "Epoch 85/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.1251 - val_loss: 0.1018\n",
      "Epoch 86/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.1208 - val_loss: 0.0926\n",
      "Epoch 87/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.1199 - val_loss: 0.0921\n",
      "Epoch 88/600\n",
      "426/426 [==============================] - 0s 129us/sample - loss: 0.1110 - val_loss: 0.0928\n",
      "Epoch 89/600\n",
      "426/426 [==============================] - 0s 126us/sample - loss: 0.1102 - val_loss: 0.1089\n",
      "Epoch 90/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.1186 - val_loss: 0.1142\n",
      "Epoch 91/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.1332 - val_loss: 0.0924\n",
      "Epoch 92/600\n",
      "426/426 [==============================] - 0s 119us/sample - loss: 0.1119 - val_loss: 0.0979\n",
      "Epoch 93/600\n",
      "426/426 [==============================] - 0s 227us/sample - loss: 0.1237 - val_loss: 0.1095\n",
      "Epoch 94/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.1189 - val_loss: 0.0956\n",
      "Epoch 95/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.1044 - val_loss: 0.0984\n",
      "Epoch 96/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.1029 - val_loss: 0.0985\n",
      "Epoch 97/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.1099 - val_loss: 0.1039\n",
      "Epoch 98/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.1006 - val_loss: 0.0964\n",
      "Epoch 99/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.1008 - val_loss: 0.0944\n",
      "Epoch 100/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.1170 - val_loss: 0.1009\n",
      "Epoch 101/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0868 - val_loss: 0.1071\n",
      "Epoch 102/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.1092 - val_loss: 0.0984\n",
      "Epoch 103/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.1009 - val_loss: 0.0978\n",
      "Epoch 104/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.1115 - val_loss: 0.0962\n",
      "Epoch 105/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.1131 - val_loss: 0.0908\n",
      "Epoch 106/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.1123 - val_loss: 0.1015\n",
      "Epoch 107/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.1239 - val_loss: 0.0948\n",
      "Epoch 108/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.1331 - val_loss: 0.0981\n",
      "Epoch 109/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0994 - val_loss: 0.0979\n",
      "Epoch 110/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0985 - val_loss: 0.0983\n",
      "Epoch 111/600\n",
      "426/426 [==============================] - 0s 110us/sample - loss: 0.0984 - val_loss: 0.1014\n",
      "Epoch 112/600\n",
      "426/426 [==============================] - 0s 173us/sample - loss: 0.1093 - val_loss: 0.0942\n",
      "Epoch 113/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0792 - val_loss: 0.0932\n",
      "Epoch 114/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.1083 - val_loss: 0.1028\n",
      "Epoch 115/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0918 - val_loss: 0.1022\n",
      "Epoch 116/600\n",
      "426/426 [==============================] - 0s 98us/sample - loss: 0.0852 - val_loss: 0.0967\n",
      "Epoch 117/600\n",
      "426/426 [==============================] - 0s 159us/sample - loss: 0.1064 - val_loss: 0.0949\n",
      "Epoch 118/600\n",
      "426/426 [==============================] - 0s 96us/sample - loss: 0.0930 - val_loss: 0.0959\n",
      "Epoch 119/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0940 - val_loss: 0.1052\n",
      "Epoch 120/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0981 - val_loss: 0.1088\n",
      "Epoch 121/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.1067 - val_loss: 0.0965\n",
      "Epoch 122/600\n",
      "426/426 [==============================] - 0s 84us/sample - loss: 0.0979 - val_loss: 0.1074\n",
      "Epoch 123/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0774 - val_loss: 0.1027\n",
      "Epoch 124/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0824 - val_loss: 0.1023\n",
      "Epoch 125/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0790 - val_loss: 0.0972\n",
      "Epoch 126/600\n",
      "426/426 [==============================] - 0s 89us/sample - loss: 0.0842 - val_loss: 0.1033\n",
      "Epoch 127/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0845 - val_loss: 0.1214\n",
      "Epoch 128/600\n",
      "426/426 [==============================] - 0s 87us/sample - loss: 0.0857 - val_loss: 0.1187\n",
      "Epoch 129/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.1056 - val_loss: 0.0981\n",
      "Epoch 130/600\n",
      "426/426 [==============================] - 0s 91us/sample - loss: 0.0822 - val_loss: 0.1039\n",
      "Epoch 00130: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19c68e6c7b8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=600, validation_data=(X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19c691054e0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history) #much better\n",
    "loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54  1]\n",
      " [ 3 85]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        55\n",
      "           1       0.99      0.97      0.98        88\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
